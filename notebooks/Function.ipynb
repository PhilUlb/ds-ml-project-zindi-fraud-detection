{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b8314f0-9c0b-47d5-8240-dca69127733d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas_profiling import ProfileReport\n",
    "import numpy as np\n",
    "\n",
    "import ipywidgets\n",
    "\n",
    "import matplotlib\n",
    "#matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import f1_score, make_scorer, recall_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3ed9cc-550f-4204-9975-4bc2eb3ab60c",
   "metadata": {},
   "source": [
    "# Create Dataset and Train, Test, Split including SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb588b7e-f20d-4250-9963-0f42a4753660",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/training.csv\")\n",
    "df = df.drop([\"CurrencyCode\",\"CountryCode\"], axis=1) # identical value across all entries\n",
    "df.set_index(\"TransactionId\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b22de204-dfe7-4332-b77c-996bf082473c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns = [\n",
    " 'ProviderId',\n",
    " 'ProductId',\n",
    " 'ProductCategory',\n",
    " 'ChannelId',\n",
    " 'PricingStrategy']\n",
    "\n",
    "df_dummies = pd.get_dummies(df, columns=cat_columns, drop_first = True)\n",
    "df_dummies.head()\n",
    "\n",
    "baseline = df_dummies.drop([\"BatchId\", \"AccountId\", \"SubscriptionId\", \"CustomerId\", \"TransactionStartTime\"], axis=1)\n",
    "baseline_short = baseline.head(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "77a60d3d-7344-48ca-bd2d-34d424dd6954",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95662, 44)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2ada8562-8ce7-4945-a6e1-5b92e180eb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(dataset=baseline, RSEED=0):\n",
    "    #Define features X and target variable y\n",
    "    \n",
    "    RSEED=0\n",
    "    X = dataset.loc[:, dataset.columns != 'FraudResult']\n",
    "    y = dataset[\"FraudResult\"]\n",
    "    \n",
    "    #Train, Test, Split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=RSEED)\n",
    "    \n",
    "    # Balancing with SMOTE\n",
    "    sm = SMOTE(random_state=RSEED)\n",
    "    X_train_balanced, y_train_balanced = sm.fit_resample(X_train, y_train)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, X_train_balanced, y_train_balanced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2699665a-0cb2-486d-9c42-37ad6ec6f4e1",
   "metadata": {},
   "source": [
    "# Get best Hyperparameters for DecisionTree, RandomForest and KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "378befda-827b-4ede-b180-2fff2ba00308",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting best parameters regarding models\n",
    "def best_hyperparameter(X_train=X_train_balanced, y_train=y_train_balanced, RSEED=0): \n",
    "    \n",
    "    #Creating Scorer for optimization\n",
    "    f1 = make_scorer(f1_score)\n",
    "    matthews_coeff = make_scorer(matthews_corrcoef)\n",
    "    recall = make_scorer(recall_score)\n",
    "    \n",
    "    #Decision Tree\n",
    "    start_time = datetime.now()\n",
    "\n",
    "    param_grid_dt = [{'criterion': ['entropy', 'gini'], \n",
    "                      'max_depth': [3,6,9],\n",
    "                     'min_samples_leaf': [2,5,10]}]\n",
    "    estimator_dt = DecisionTreeClassifier(random_state=RSEED)\n",
    "    rs_dt = GridSearchCV(estimator_dt, param_grid_dt, scoring=f1)\n",
    "    rs_dt.fit(X_train, y_train)\n",
    "    best_params_dt = estimator_dt.set_params(**rs_dt.best_params_)\n",
    "    \n",
    "\n",
    "    end_time = datetime.now()\n",
    "    print('Duration DT: {}'.format(end_time - start_time))\n",
    "    \n",
    "    \n",
    "    start_time = datetime.now()\n",
    "    #Random Forest  \n",
    "    param_grid_rf = {\n",
    "    'n_estimators': np.linspace(10, 200).astype(int),\n",
    "    'max_depth': [None] + list(np.linspace(3, 20).astype(int)),\n",
    "    'max_features': ['auto', 'sqrt', None] + list(np.arange(0.5, 1, 0.1)),\n",
    "    'max_leaf_nodes': [None] + list(np.linspace(10, 50, 500).astype(int)),\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'bootstrap': [True, False]}\n",
    "    \n",
    "    estimator_rf = RandomForestClassifier(random_state=RSEED)\n",
    "    rs_rf = RandomizedSearchCV(estimator_rf, param_grid_rf, n_jobs = -1, n_iter=5,\n",
    "                               cv = 3, verbose = 5, scoring=f1, random_state=RSEED)\n",
    "    rs_rf.fit(X_train, y_train)\n",
    "    best_params_rf = estimator_rf.set_params(**rs_rf.best_params_)\n",
    "    \n",
    "    end_time = datetime.now()\n",
    "    print('Duration RF: {}'.format(end_time - start_time))\n",
    "    \n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    ''' \n",
    "    #KNN\n",
    "    param_grid_knn = [{'n_neighbors': [5], \n",
    "                      'metric': ['minkowski'],\n",
    "                      'p': [1,2]}]\n",
    "    estimator_knn = KNeighborsClassifier()\n",
    "    rs_knn = GridSearchCV(estimator_knn, param_grid_knn,\n",
    "                            scoring=matthews_coeff, verbose=4)\n",
    "    rs_knn.fit(X_train, y_train)\n",
    "    best_params_knn = estimator_knn.set_params(**rs_knn.best_params_)\n",
    "    \n",
    "    end_time = datetime.now()\n",
    "    print('Duration KNN: {}'.format(end_time - start_time))\n",
    "    '''\n",
    "    \n",
    "    return best_params_dt, best_params_rf, best_params_knn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5c37ee-846a-41ed-8dc5-4eaf48dd7a78",
   "metadata": {},
   "source": [
    "# Compare different models (DecTree, RF, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f6b5f4f1-a6af-40c9-8d13-7bbcb1aed5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(dataset=baseline, RSEED=0):\n",
    "    \n",
    "    #Prepare data for given dataset, conduct test, train split and oversample via SMOTE\n",
    "    X_train, X_test, y_train, y_test, X_train_balanced, y_train_balanced = prepare_data(dataset)    \n",
    "    \n",
    "    #Get best parameter via GridSearch\n",
    "    best_params_dt, best_params_rf, best_params_knn = best_hyperparameter(X_train, y_train)\n",
    "    \n",
    "    #Defining models\n",
    "    dtree_baseline = DecisionTreeClassifier(random_state=RSEED)\n",
    "    dtree_sm_opt = best_params_dt\n",
    "    RandomForest_sm_opt = best_params_rf\n",
    "    log_reg_sm = LogisticRegression(max_iter=1000)\n",
    "    KNN_sm_euclidian = KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=2)\n",
    "    KNN_sm_manhattan = KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=1)\n",
    "    KNN_sm_minkowski3 = KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=3)\n",
    "    AdaBoost_sm = AdaBoostClassifier(n_estimators=100, random_state=RSEED)\n",
    "    \n",
    "    #Print data for basline model: DecisionTree\n",
    "    dtree_baseline.fit(X_train, y_train)\n",
    "    predictions = dtree_baseline.predict(X_test) \n",
    "    print(\"Results for model: \\n {}\".format(dtree_baseline))\n",
    "    print(\"\\n Confusion Matrix: \\n {}\".format(confusion_matrix(y_test, predictions)))\n",
    "    print(\"\\n Classification report: \\n {}\".format(classification_report(y_test, predictions)))\n",
    "    print(\"\\n Matthew Coefficient: \\n {}\".format(matthews_corrcoef(y_test, predictions)))\n",
    "    print(\"\\n\\n\")\n",
    "    \n",
    "    #Loop for further models using SMOTE data\n",
    "    print(\"All further results are oversampled via SMOTE:\\n\")\n",
    "           \n",
    "    #Putting models in a list\n",
    "    models = [dtree_sm_opt, RandomForest_sm_opt, AdaBoost_sm] #,log_reg_sm, KNN_sm_manhattan, KNN_sm_minkowski3, KNN_sm_euclidian, \n",
    "    \n",
    "    #Looping through models\n",
    "    for model in models:\n",
    "\n",
    "        model.fit(X_train_balanced, y_train_balanced)\n",
    "        predictions = model.predict(X_test) \n",
    "    \n",
    "        print(\"Results for model: \\n {}\".format(model))\n",
    "        print(\"\\n Confusion Matrix: \\n {}\".format(confusion_matrix(y_test, predictions)))\n",
    "        print(\"\\n Classification report: \\n {}\".format(classification_report(y_test, predictions)))\n",
    "        print(\"\\n Matthew Coefficient: \\n {}\".format(matthews_corrcoef(y_test, predictions)))\n",
    "        print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2f8a9e4b-a192-43b3-ae04-9a7af89cdee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration DT: 0:00:03.944101\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "Duration RF: 0:00:04.490746\n",
      "Results for model: \n",
      " DecisionTreeClassifier(random_state=1)\n",
      "\n",
      " Confusion Matrix: \n",
      " [[28636     5]\n",
      " [   13    45]]\n",
      "\n",
      " Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     28641\n",
      "           1       0.90      0.78      0.83        58\n",
      "\n",
      "    accuracy                           1.00     28699\n",
      "   macro avg       0.95      0.89      0.92     28699\n",
      "weighted avg       1.00      1.00      1.00     28699\n",
      "\n",
      "\n",
      " Matthew Coefficient: \n",
      " 0.8353243456716077\n",
      "\n",
      "\n",
      "\n",
      "All further results are oversampled via SMOTE:\n",
      "\n",
      "Results for model: \n",
      " DecisionTreeClassifier(criterion='entropy', max_depth=9, min_samples_leaf=2,\n",
      "                       random_state=0)\n",
      "\n",
      " Confusion Matrix: \n",
      " [[28596    45]\n",
      " [    5    53]]\n",
      "\n",
      " Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     28641\n",
      "           1       0.54      0.91      0.68        58\n",
      "\n",
      "    accuracy                           1.00     28699\n",
      "   macro avg       0.77      0.96      0.84     28699\n",
      "weighted avg       1.00      1.00      1.00     28699\n",
      "\n",
      "\n",
      " Matthew Coefficient: \n",
      " 0.7022713428436449\n",
      "\n",
      "\n",
      "\n",
      "Results for model: \n",
      " RandomForestClassifier(max_depth=7, max_features=0.7999999999999999,\n",
      "                       max_leaf_nodes=41, min_samples_split=5, n_estimators=25,\n",
      "                       random_state=0)\n",
      "\n",
      " Confusion Matrix: \n",
      " [[28586    55]\n",
      " [    2    56]]\n",
      "\n",
      " Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     28641\n",
      "           1       0.50      0.97      0.66        58\n",
      "\n",
      "    accuracy                           1.00     28699\n",
      "   macro avg       0.75      0.98      0.83     28699\n",
      "weighted avg       1.00      1.00      1.00     28699\n",
      "\n",
      "\n",
      " Matthew Coefficient: \n",
      " 0.6971883337048119\n",
      "\n",
      "\n",
      "\n",
      "Results for model: \n",
      " AdaBoostClassifier(n_estimators=100, random_state=1)\n",
      "\n",
      " Confusion Matrix: \n",
      " [[28521   120]\n",
      " [    2    56]]\n",
      "\n",
      " Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     28641\n",
      "           1       0.32      0.97      0.48        58\n",
      "\n",
      "    accuracy                           1.00     28699\n",
      "   macro avg       0.66      0.98      0.74     28699\n",
      "weighted avg       1.00      1.00      1.00     28699\n",
      "\n",
      "\n",
      " Matthew Coefficient: \n",
      " 0.5530004581159842\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "compare(baseline, RSEED=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8314f0-9c0b-47d5-8240-dca69127733d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas_profiling import ProfileReport\n",
    "import numpy as np\n",
    "\n",
    "import ipywidgets\n",
    "\n",
    "import matplotlib\n",
    "#matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "from sklearn.metrics import f1_score, make_scorer, recall_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3ed9cc-550f-4204-9975-4bc2eb3ab60c",
   "metadata": {},
   "source": [
    "# Create Dataset and Train, Test, Split including SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb588b7e-f20d-4250-9963-0f42a4753660",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/training_final.csv\")\n",
    "#df = df.drop([\"CurrencyCode\",\"CountryCode\"], axis=1) # identical value across all entries\n",
    "df.set_index(\"TransactionId\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80dcc479-1d88-475f-b52a-96c65746acd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22de204-dfe7-4332-b77c-996bf082473c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns = [\n",
    " 'ProviderId',\n",
    " 'ProductId',\n",
    " 'ProductCategory',\n",
    " 'ChannelId',\n",
    " 'PricingStrategy',\n",
    " 'BookingType',\n",
    " 'Interval']\n",
    "\n",
    "df_dummies = pd.get_dummies(df, columns=cat_columns, drop_first = True)\n",
    "df_dummies.head()\n",
    "\n",
    "baseline = df_dummies.drop([\"BatchId\", \"AccountId\", \"SubscriptionId\", \"CustomerId\", \"TransactionStartTime\",'ProviderId-AccountId'], axis=1)\n",
    "baseline_short = baseline.head(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a90bb45-972c-4c48-bda8-d02b0a138f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ada8562-8ce7-4945-a6e1-5b92e180eb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(dataset=baseline, RSEED=0):\n",
    "    #Define features X and target variable y\n",
    "    \n",
    "    RSEED=0\n",
    "    X = dataset.loc[:, dataset.columns != 'FraudResult']\n",
    "    y = dataset[\"FraudResult\"]\n",
    "    \n",
    "    #Train, Test, Split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=RSEED)\n",
    "    \n",
    "    # Balancing with SMOTE\n",
    "    #sm = RandomOverSampler(sampling_strategy='minority')\n",
    "    sm = SMOTE(random_state=RSEED)\n",
    "    X_train_balanced, y_train_balanced = sm.fit_resample(X_train, y_train)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, X_train_balanced, y_train_balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b3857e-fd89-48ea-a920-8cbd5dda9466",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, X_train_balanced, y_train_balanced = prepare_data(baseline)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2699665a-0cb2-486d-9c42-37ad6ec6f4e1",
   "metadata": {},
   "source": [
    "# Get best Hyperparameters for DecisionTree, RandomForest and KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378befda-827b-4ede-b180-2fff2ba00308",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting best parameters regarding models\n",
    "def best_hyperparameter(X_train, y_train, RSEED=0): \n",
    "    \n",
    "    #Creating Scorer for optimization\n",
    "    f1 = make_scorer(f1_score)\n",
    "    matthews_coeff = make_scorer(matthews_corrcoef)\n",
    "    recall = make_scorer(recall_score)\n",
    "    \n",
    "    #Decision Tree\n",
    "    start_time = datetime.now()\n",
    "\n",
    "    param_grid_dt = [{'criterion': ['entropy', 'gini'], \n",
    "                      'max_depth': [3,6,9],\n",
    "                     'min_samples_leaf': [2,5,10]}]\n",
    "    estimator_dt = DecisionTreeClassifier(random_state=RSEED)\n",
    "    rs_dt = GridSearchCV(estimator_dt, param_grid_dt, scoring=f1)\n",
    "    rs_dt.fit(X_train, y_train)\n",
    "    best_params_dt = estimator_dt.set_params(**rs_dt.best_params_)\n",
    "    \n",
    "\n",
    "    end_time = datetime.now()\n",
    "    print('Duration DT: {}'.format(end_time - start_time))\n",
    "    \n",
    "    \n",
    "    start_time = datetime.now()\n",
    "    #Random Forest  \n",
    "    param_grid_rf = {\n",
    "    'n_estimators': np.linspace(10, 200).astype(int),\n",
    "    'max_depth': [None] + list(np.linspace(3, 20).astype(int)),\n",
    "    'max_features': ['auto', 'sqrt', None] + list(np.arange(0.5, 1, 0.1)),\n",
    "    'max_leaf_nodes': [None] + list(np.linspace(10, 50, 500).astype(int)),\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'bootstrap': [True, False]}\n",
    "    \n",
    "    estimator_rf = RandomForestClassifier(random_state=RSEED)\n",
    "    rs_rf = RandomizedSearchCV(estimator_rf, param_grid_rf, n_jobs = -1, n_iter=5,\n",
    "                               cv = 3, verbose = 1, scoring=f1, random_state=RSEED)\n",
    "    rs_rf.fit(X_train, y_train)\n",
    "    best_params_rf = estimator_rf.set_params(**rs_rf.best_params_)\n",
    "    \n",
    "    end_time = datetime.now()\n",
    "    print('Duration RF: {}'.format(end_time - start_time))\n",
    "    \n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    ''' \n",
    "    #KNN\n",
    "    param_grid_knn = [{'n_neighbors': [5], \n",
    "                      'metric': ['minkowski'],\n",
    "                      'p': [1,2]}]\n",
    "    estimator_knn = KNeighborsClassifier()\n",
    "    rs_knn = GridSearchCV(estimator_knn, param_grid_knn,\n",
    "                            scoring=matthews_coeff, verbose=4)\n",
    "    rs_knn.fit(X_train, y_train)\n",
    "    best_params_knn = estimator_knn.set_params(**rs_knn.best_params_)\n",
    "    \n",
    "    end_time = datetime.now()\n",
    "    print('Duration KNN: {}'.format(end_time - start_time))\n",
    "    '''\n",
    "    \n",
    "    return best_params_dt, best_params_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5c37ee-846a-41ed-8dc5-4eaf48dd7a78",
   "metadata": {},
   "source": [
    "# Compare different models (DecTree, RF, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b5f4f1-a6af-40c9-8d13-7bbcb1aed5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(dataset=baseline, RSEED=0, param_search=False, smote=True):\n",
    "    \n",
    "    print(\"Settings: \\n\")\n",
    "    print(\"RSEED: {}\".format(RSEED))\n",
    "    print(\"Hyperparameter Search:{}\".format(param_search))\n",
    "    print(\"Smote: {}\".format(smote))\n",
    "    \n",
    "    #Prepare data for given dataset, conduct test, train split and oversample via SMOTE\n",
    "    X_train, X_test, y_train, y_test, X_train_balanced, y_train_balanced = prepare_data(dataset)    \n",
    "    \n",
    "    #Defining models\n",
    "    \n",
    "    #Without smote\n",
    "    dtree_baseline = DecisionTreeClassifier(random_state=RSEED)\n",
    "    RandomForest = RandomForestClassifier(random_state=RSEED)\n",
    "    KNN_euclidian = KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=2)\n",
    "    AdaBoost = AdaBoostClassifier(n_estimators=100, random_state=RSEED)\n",
    "    logreg = LogisticRegression(random_state=0)\n",
    "    \n",
    "    models = [dtree_baseline, RandomForest, KNN_euclidian, AdaBoost, logreg]\n",
    "    \n",
    "    #Print data for models without smote\n",
    "    for model in models:\n",
    "        model.fit(X_train, y_train)\n",
    "        predictions = model.predict(X_test) \n",
    "        \n",
    "        print(\"\\n\\n\")\n",
    "        print(\"Results for model: \\n {}\".format(model))\n",
    "        print(\"\\n Confusion Matrix: \\n {}\".format(confusion_matrix(y_test, predictions)))\n",
    "        print(\"\\n Classification report: \\n {}\".format(classification_report(y_test, predictions)))\n",
    "        print(\"\\n Matthew Coefficient: \\n {}\".format(matthews_corrcoef(y_test, predictions)))\n",
    "        \n",
    "    \n",
    "    if smote is True:\n",
    "        print(\"All further results are oversampled via SMOTE:\\n\")\n",
    "    \n",
    "        #Looping through models using SMOTE data: balanced\n",
    "        for model in models:\n",
    "            model.fit(X_train_balanced, y_train_balanced)\n",
    "            predictions = model.predict(X_test) \n",
    "    \n",
    "            print(\"\\n\\n\")\n",
    "            print(\"Results for model: \\n {}\".format(model))\n",
    "            print(\"Smote: {}\".format(smote))\n",
    "            print(\"\\n Confusion Matrix: \\n {}\".format(confusion_matrix(y_test, predictions)))\n",
    "            print(\"\\n Classification report: \\n {}\".format(classification_report(y_test, predictions)))\n",
    "            print(\"\\n Matthew Coefficient: \\n {}\".format(matthews_corrcoef(y_test, predictions)))\n",
    "            \n",
    "            \n",
    "    if param_search is True:\n",
    "        print(\"Hyperparameter-Search running for Decision Tree and Random Forest.\")\n",
    "        #print(\"KNN also analyzed with Manhattan and Minkowski Metric...\")\n",
    "        if smote is True:\n",
    "            #Get best parameter via GridSearch\n",
    "            best_params_dt, best_params_rf = best_hyperparameter(X_train_balanced, y_train_balanced)\n",
    "        if smote is False: \n",
    "            best_params_dt, best_params_rf = best_hyperparameter(X_train, y_train)\n",
    "            \n",
    "        dtree_sm_opt = best_params_dt\n",
    "        RandomForest_sm_opt = best_params_rf\n",
    "        #KNN_sm_manhattan = KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=1)\n",
    "        #KNN_sm_minkowski3 = KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=3)\n",
    "        \n",
    "        models_sm_opt = [dtree_sm_opt, RandomForest_sm_opt] #KNN_sm_manhattan, KNN_sm_minkowski3\n",
    "        \n",
    "        #Loop for further models using SMOTE data\n",
    "        print(\"All further results are results of best hyperparameter search:\\n\")\n",
    "    \n",
    "        #Looping through models\n",
    "        for model in models_sm_opt:\n",
    "\n",
    "            model.fit(X_train_balanced, y_train_balanced)\n",
    "            predictions = model.predict(X_test) \n",
    "    \n",
    "            print(\"\\n\\n\")\n",
    "            print(\"Results for model: \\n {}\".format(model))\n",
    "            print(\"Smote: {}\".format(smote))\n",
    "            print(\"Hyperparameter Search:{}\".format(param_search))\n",
    "            print(\"\\n Confusion Matrix: \\n {}\".format(confusion_matrix(y_test, predictions)))\n",
    "            print(\"\\n Classification report: \\n {}\".format(classification_report(y_test, predictions)))\n",
    "            print(\"\\n Matthew Coefficient: \\n {}\".format(matthews_corrcoef(y_test, predictions)))\n",
    "            \n",
    "    print(\"\\n END\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8a9e4b-a192-43b3-ae04-9a7af89cdee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare(baseline, param_search=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2742a5dc-5bb2-4743-89c9-91151df06b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(\"../data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6564c1a-cf20-46b2-a11d-c3196b660499",
   "metadata": {},
   "outputs": [],
   "source": [
    "#baseline.to_csv('../data/training_final.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba688a3f-192d-4692-b0ca-fe8971aa914e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
